---
title: "Notebook"
author: "A.Amstutz"
date: "2023-10-16"
output: 
  html_document:
    keep_md: yes
    toc: yes
    toc_float: yes
    code_folding: hide
  pdf_document:
    toc: yes
---

# The Guidance
Richard Riley et al. Individual Participant Data Meta-Analysis: A Handbook for Healthcare Research
https://www.ipdma.co.uk/description 


# General
1. Use F&G also for sens-analysis (sustained discharge)?
2. Re QoL: Wait for more trials first. Find out more about the QoL measure used, besides bari-solidact.
3. ACTT2:
* For Country only Region -> Non-US Site n=148 and US Site n=885: "There were 67 trial sites in 8 countries: the United States (55 sites), Singapore (4), South Korea (2), Mexico (2), Japan (1), Spain (1), the United Kingdom (1), and Denmark (1)."


## Adjustments across all endpoints and across all trials
1. "When including prognostic factors that are recorded on a continuous scale, they should be analysed on their continuous scale, as dichotomisation or categorisation is arbitrary and loses power. Thus, adjustment for continuous prognostic factors should at least assume a linear trend." (p. 103)
2. "Where conditional treatment effects are of interest for meta-analysis and the pre-defined prognostic (adjustment) factors are systematically missing in some trials, then it is sensible to use the subset of factors that are consistently recorded. In particular, for treatment effects defined by odds ratios or hazard ratios, adjusting for different sets of prognostic factors is problematic due to non-collapsibility (Section 5.2.4); it will make the subsequent summary meta-analysis result hard to interpret and impact upon (often increase) the between-trial heterogeneity in treatment effect. Even for collapsible measures (such as mean differences and risk ratios), the weighting of a particular trial in the meta-analysis may be influenced by whether a full or reduced set of prognostic factors is used, and so it is better to be consistent across trials." (p. 106) 
3. "Partially missing prognostic factor values in a trial can be handled (in each trial separately) by using mean imputation or the missing indicator method, which – although rightly criticised for use in other medical research applications – is actually appropriate for randomised trials aiming to estimate a treatment effect. Again, multiple imputation is a possible alternative (Chapter 18), for example to utilise additional prognostic factors and outcomes available in the IPD, or even to consider missing not at random assumptions." (p. 106) 

a) age

b) clinical status 2-5:
* Not all trials enrolled all stages
* Numeric or factor?

* *__Decision 01.11.23__*: Don't assume linearity (numeric), use it as a factor (incl. when centering in one-stage?)
c) COVID comedication: toci, dexa, rdv
* BariSolidact: Only 1 with toci, 8 with rdv, nearly all with dexa
* ACTT2: Noone toci, Noone dexa, all in intervention also had rdv
* Ghazaeian: Noone toci, all rdv, all dexa
* Tofacov: Noone toci, nearly all rdv, nearly all dexa
* Covinib: Noone toci, noone rdv, a few dexa

* *__Decision 01.11.23__*: Drop this adjustment variable. Justification: consistency across trials/models; adjustment would not be by co-medication, but by trial; and collinearity in models. Unadjusted analyses as sens-analysis (if needed).


## Subgroup analyses
1. Respiratory support & comedication & comorbidity: Numeric or factor? 
* *__Decision 29.11.23__*: Dichotomize respiratory support according to previous IPDMA and due to clinical hypothesis and sparse/non-existent data in some categories.

2. CRP: truncated or not?
* *__Decision 29.11.23__*: Not.

3. Rare event strategy? See e.g. firth regression in Ghazaeian, respiratory support, all 7 events only in clinstatus_baseline == 3
* *__Decision 29.11.23__*: Firth regression.

4. Assumptions about linearity and common vs random effects?
* *__Decision xx.01.24__*: ...

*__Chapter7__* Using IPD Meta-Analysis to Examine Interactions between Treatment Effect and Participant-level Covariates
1. When done properly, an IPD meta-analysis avoids using across-trial information from a meta-regression of the observed treatment effects (based on all trial participants) and aggregated values of participant-level covariates (such as mean age, proportion male). Such analyses are prone to aggregation bias, low power, and may not reflect actual interactions at the participant level ("daft"). Instead it should aim to estimate the interaction between treatment effect and a covariate measured at the participant-level ("deft").
2. A two-stage IPD approach to estimating treatment-covariate interactions avoids aggregation bias by estimating treatment-covariate interactions in each trial separately, and then synthesising them in the second stage. This ensures that only within-trial information is used.
3. A one-stage IPD meta-analysis to the estimation of treatment-covariate interactions must ensure that within-trial and across-trial information are separated out, by either (i) stratifying all nuisance parameters by trial, or (ii) centering the covariate by its mean and allowing the mean covariate value to explain between-trial heterogeneity.
4. Many current IPD meta-analysis projects apply a one-stage model that amalgamates within-trial and across-trial information; this is not recommended.
5. If interactions do exist, they are more likely to be detected when continuous covariates and outcomes are analysed on their continuous scale. 6. Treatment-covariate interactions may be non-linear (e.g. U- or J-shaped), and should be investigated, for example using a two-stage multivariate IPD meta-analysis summarising interactions defined by a restricted cubic spline function.
7. Treatment-covariate interactions may depend on the scale of analysis; for example, they may arise on the odds ratio scale, even when there is no interaction on the risk ratio scale.
8. For example, Berlin et al. examined the effect of elevated panel reactive antibodies on the effective- ness of anti-lymphocyte antibody induction. Applying meta-regression model (7.2), and thus examining the association of a trial’s treatment effect (as derived using all participants) and the proportion of trial participants with elevated antibodies, they found no evidence of an association (difference in log odds ratio = 0.01, p = 0.68). However, when IPD were obtained and the treatment-covariate interaction investigated at the participant level using within-trial information, they found a substantial difference in the treatment effect (log odds ratio) between elevated and non-elevated participants (difference in log odds ratio = –1.33, p = 0.01).
9. Aggregation bias / ecological bias / ecological fallacy: Observed across-trial associations do not properly reflect the participant-level relationships within trials. For example, meta-regression may identify that trials with a larger mean age have a larger treatment effect; however, those trials with a higher mean age might also have a higher intended dose of the treatment, and therefore the larger effect in such trials could be due to a higher dose rather than having older participants
10. Do Not Quantify Interactions by Comparing Meta-Analysis Results for Subgroups. It may be tempting to perform a two-stage IPD meta-analysis of the treatment effect in each subgroup separately (e.g. men, women; smokers, non-smokers), and then compare them via a statistical test or by calculating their difference. This is a common approach as it is apparently simple and leads to nice graphical displays for each subgroup, as illustrated for the effect of tamoxifen in ER positive and negative subgroups in Box 7.1. However, the approach is flawed, as it amalgamates within-trial and across-trial information; Fisher et al. thus call it a ‘deluded’ analysis.

11. Two-stage:
* Estimation of the appropriate model in each trial, for example using maximum likelihood estimation (potentially with Firth’s correction or another penalisation method if sparse data bias is a concern) produces a treatment-covariate interaction estimate, γWi, and its variance, var γWi. Then, in the second stage the γWi values are combined across trials in either a common-effect model (i.e. the true interaction is assumed the same in all trials), or a random-effects model (i.e. the true interactions are assumed random across trials).
* Estimation methods are as described in Chapter 5; for example, model (7.7) can be estimated using REML with subsequent confidence intervals derived using the HKSL approach or, if wider, the standard approach (Section 5.3.7).
* For a continuous outcome modelled using the linear regression of model (7.3) in the first stage, γW represents a difference in mean difference; for a binary outcome modelled using the logistic regression of model (7.4) in the first stage, γW represents a difference in log odds ratios (i.e. exp γW gives a ratio of odds ratios); and for a time-to-event outcome modelled using Cox regression model (7.5) in the first stage, γW represents a difference in log hazard ratios (i.e. exp γW is a ratio of hazard ratios).

12. One-stage:
* A one-stage IPD meta-analysis can also be used to summarise treatment-covariate interactions, by extending the framework introduced in Chapter 6. However, this is not straightforward. Simply including a treatment-covariate interaction term may introduce aggregation bias, as it allows across-trial information to contribute toward the summary interaction estimate, in combination with within-trial information. We do not recommend it, as the influence of the across-trial information may bias results, and lead to misleading conclusions about whether a particular treatment-covariate interaction truly exists at the participant-level. Unfortunately, many IPD meta-analysis researchers adopt this approach,148,257,258 often unknowingly.
* There are two main ways of preventing amalgamation of within-trial and across-trial information when estimating the treatment-covariate interaction in a one-stage IPD meta-analysis model:
a) Center the covariate zij about its trial-specific mean, zi, and add an additional term which allows the covariate means (zi to explain between-trial heterogeneity in the treatment effect; or
b) Stratify by trial each of the other parameters outside the interaction term, including the parameter representing the reference treatment effect (i.e. the treatment effect at the covariate’s reference value, typically zij = 0 or, if the covariate is centered, zij = zi).
* Stratified: In this model, each of the nuisance parameters are stratified by trial, and random effects are placed only on the within-trial interaction. This stratification of nuisance parameters by trial, in particular β2i representing the treatment effect at the covariate’s reference value, ensures that γW only contains within-trial information. It also closely reflects the two-stage approach, where all nuisance parameters are naturally stratified by trial as they are estimated in each trial separately in the first stage. Note that if one-stage model was extended to adjust for other covariates (e.g. prognostic factors), ideally they should also be stratified by trial. Further, although no longer needed to remove aggregation bias, centering all covariates (including the treatment covariate xij) in the model may still be sensible, for example to improve maximum likelihood estimation
* Center and covariate mean: Inclusion of the γAzi term, together with the centering of zij within the interaction term, disentangles γW (the within-trial interaction of interest) and γA (the across-trial association) such that they are uncorrelated with each other, and thus γW will be based solely on within-trial information
* The estimate of γW should usually be very similar regardless of whether approach (a) or (b) is taken. However, (b) assume the β2i have a mean of α + γAzi , and so the γA represents the slope of an assumed linear across-trial relationship of the treatment effect and the covariate mean z j. Further research is needed to establish whether any consequences arise when the true relationship across trials is non-linear. Usually the across-trial relationship will not be of interest, in which case approach (a) should be used as it avoids making any such assumptions.

13. Circles are recommended by Fisher et al. to help distinguish a forest plot of interaction estimates from a standard forest plot of treatment effect estimates, for which squares are typically used

14. Handling of Categorical or Ordinal Covariates: With an ordinal covariate, the simplest model conceptually is to assume a linear trend in the treatment effect across the categories. This can be done by simply applying the methods previously described, treating the categorical covariate exactly as if it were continuous. In this case, covariates will usually be coded using constant intervals, that is, 1, 2, 3 or similar. However, non-constant intervals could also be used with sufficient justification; for example, if one of the extreme categories were to be considered as being very different from the others. As before, to avoid the potential for aggregation bias, a two-stage approach can be used to estimate and then combine interactions between treatment effect and the ordinal variable. Alternatively, a one-stage approach should stratify the treatment variable and other nuisance parameters by trial, and/or the covariate should be centered around its trial-level mean – which in this context will be dependent upon the chosen coding system. The alternative, applicable to either categorical or ordinal covariates, is to analyse the difference in treatment effect between each category and a single reference category. This involves meta-analysing multiple effects simultaneously, and is therefore handled by a one-stage model with the treatment variable and the covariate each interacted with the trial identifier, or a two-stage approach with multivariate meta-analysis in the second stage. As described for continuous covariates in Section 7.6.1, it is preferable to analyse categorical and ordinal covariates without further categorisation. However, in some circumstances it may be unavoidable. For example, if data are sparse in certain categories, it may be necessary to make a decision either to remove those categories from the analysis, or to collapse them with adjacent categories, in order to obtain interpretable results.

15. Interactions May Depend on the Scale of Analysis: Further caution is needed when examining changes of odds ratios across subgroups to identify treatment-covariate interactions. The treatment effect as defined by a risk ratio may be a constant across subgroups, but the odds ratio can still differ when the covariate of interest is a prognostic factor. The reason for this is that the magnitude of the odds ratio depends on the baseline risk, and the difference between the odds ratio and the risk ratio becomes more pronounced as the baseline risk becomes larger (i.e. it moves away from 0 toward 1). Therefore, if the covariate under consideration is a prognostic factor, the baseline risk of participants will depend on their value of this factor (regardless of treatment). This will lead to an interaction between the covariate and the treatment effect as measured by an odds ratio, even when there is no interaction on the risk ratio scale. This is superbly illustrated by Shrier and Pang.56 Therefore, when examining treatment-covariate interactions within a logistic regression, there needs to be consideration of this phenomenon, *especially when the outcome is not rare* for particular subgroups. The issue may also arise when comparing hazard (rate) ratios across subgroups, as these too depend on the baseline risk in each subgroup. Therefore, alternative or additional analyses that examine changes in the risk ratio across subgroups are warranted, to check if differences remain on that scale.

16. However, another approach to personalising or stratifying the use of treatments is to consider their impact on absolute risks. Those patients with the highest abso- lute risk will derive the largest absolute benefit from a treatment (e.g. greatest reduction in probability of the outcome event) when the treatment effect expressed in relative terms is the same for all patients. For example, if the relative treatment effect on mortality risk is estimated as a risk ratio of 0.5 for all patients, then a patient whose mortality risk is 0.5 will have it reduced to 0.25, but a patient whose mortality risk is 0.1 will have it reduced to 0.05. For this purpose, prognostic models are important, as these predict absolute outcome risk for a new patient condi- tional on their values of multiple predictors.

17. Once an interaction has been identified as genuine and clinically relevant, the next step is to establish how best to predict an individual patient’s treatment effect. This is a complex issue, especially when there are different sources of heterogeneity, and has received relatively little attention in the IPD meta-analysis setting, in which aggregation bias is again a concern.

18. Do Not Categorise Continuous Covariates: The usual argument for categorisation, and in particular dichotomisation, of continuous variables is to aid clinical interpretation and maintain simplicity. However, it can rarely, if ever, be justified that an individual patient whose value is just below the cut-point is completely different from a patient whose value is just above it. One example, described more fully in Section 12.5.2, shows that the loss of information by dichotomising BMI (rather than keeping as continuous) is similar to throwing away IPD from about 10 of 24 trials containing 1761 participants (about 60% of the total participants). Why spend one or two years painstakingly obtaining, cleaning and harmonising IPD from multiple trials only to throw 60% of the data just before the analysis? This is a bad idea!

19. Interactions May Be Non-linear: All the models and examples provided so far in this chapter have assumed a linear trend for the interaction of treatment and a continuous covariate. However, sometimes the interaction may be non-linear, as emphasised by Royston and Sauerbrei, and considered in detail by Kasenda et al. Therefore, non-linear interactions should routinely be evaluated when the interaction of continuous covariates and treatment effect is of interest, for example using cubic splines (Box 7.2) or fractional polynomials (Box 7.3).

20. Two-stage Multivariate IPD Meta-Analysis for Summarising Non-linear Interactions: In a two-stage approach to IPD meta-analysis of a non-linear interaction, a restricted cubic spline is fitted in each trial separately and the parameter estimates defining the interaction of this function with treatment are then combined in a multivariate meta-analysis. For instance, in the first stage of our example, we pre-defined three internal knots (at the same location in each trial) for the restricted cubic function of the association between age and final SBP in the control group, which led to three parameters per trial defining the spline function in each trial (an intercept and two slope terms). The interaction of this spline function with the treatment effect was then estimated, leading to a within-trial treatment-covariate interaction for each slope in each trial. These slope terms define the expected change (difference) in treatment effect across covariate values, relative to the chosen reference group of participants (here, 55 years old). Briefly, a restricted cubic spline is obtained by fitting a series of cubic functions and forcing them to join (and be smoothed) at certain points (called internal knots), whilst constraining the function to be linear in the tails (i.e. before the first internal knot and after the last internal knot). The magnitude and shape of the curve are defined by multiple parameters depending on the number of knots chosen. Rather than using a reference group whose covariate value is 0, it helps to center the spline variables at a meaningful value (for example, 55 years was chosen as the reference group in Figure 7.7, as it was approximately the average age across trials). Or use MFPI, Box 7.3: Fractional polynomials offer a limited but flexible set of transformations to describe the potentially non-linear association between a continuous covariate, z, and a particular outcome. Instead of assuming a linear trend, a fractional polynomial function of degree m ≥ 1 is allowed, of the form Y = α + mk = 1δkzpk , where the fractional powers p1, ..., pm are selected from a small predefined set. Royston and Sauerbrei recommend choosing powers from among {−2, −1, −0.5, 0, 0.5, 1, 2, 3}, with zx0 corresponding to ln(z). Powers are allowed to repeat in fractional polynomials; each time a power repeats, it is multiplied by another ln(z). For example, if power 3 is selected twice, z3 and z3ln(z) are used. Automated procedures in statistical software test all possible transformations of degree m to select the most appropriate transformation(s) for the data. Usually an m of 1 or 2 will suffice. See Box 7.4 for first stage of a restricted cubic spline and Box 7.5 for the second stage (multivariate meta-analysis) and plotting

21. One-stage IPD Meta-Analysis for Summarising Non-linear Interactions: A one-stage IPD meta-analysis model might also be used to examine non-linear treatment- covariate interactions. This might initially seem more intuitive, as it allows all model parameters (including the non-linear function) to be obtained in a single framework. However, in practice it is very difficult to undertake coherently. First, by modelling non-linear functions, we add further parameters to be estimated alongside the trial-specific intercepts and adjustment factors. There are also potentially multiple (correlated) random effects (e.g. one for each of the parameters of the spline function). These issues may cause estimation and convergence problems. Secondly, when centering covariates by their trial-specific means to avoid aggregation bias (i.e. building on models (7.9), (7.11) and (7.12)), the interpretation of the spline function becomes problematic. Unless all trials have the same mean covariate value, the change in treatment effect for a one-unit increase in a covariate from its mean will have a different interpretation in each trial; this will make the summary spline function uninterpretable. For these reasons, we prefer the two-stage approach for examining non-linear treatment-covariate interactions, or a one-stage approach that avoids centering by stratifying trial parameters outside the interaction term (i.e. build on models (7.10), (7.13) and (7.14)).



## How to deal with rare events and small trials
1. binary outcomes (page 99): "A problem occurs in trials that have no outcome events (or no non-events) in either the treatment group or the control group, as then the treatment effect estimate (e.g. log odds ratio or log risk ratio) and its variance cannot be calculated because the regression model cannot be fitted.32–34 Then, the meta-analyst is faced with either throwing such trials away (which might be viewed as research waste) or adding extra information to their data to allow estimates to be derived. Traditionally, the latter is addressed in a particular trial by using a continuity correction, where a small number is added to each cell of the trial’s two-by-two table (i.e. that which tabulates the number of events and non-events for the treatment and control groups). Traditionally 0.5 is the value added,35 but Sweeting et al. suggest that a ‘treatment arm’ continuity correction is more appropriate,33 which adds 1/(sample size of the opposite treatment group) to the number of event and non-events. In the IPD context, a similar approach is to add two extra participants to each group in a trial if it has zero events in either of the groups; one of the added participants has the event and the other does not have the event in each group. Then, a weighted regression analysis can be performed to analyse the extended IPD, with all participants weighted equally except the four added participants, who are given a weight according to Sweeting correction (i.e. 1/(sample size of the opposite treat- ment group)). However, this approach becomes problematic when adjusting for prognostic factors or extending to non-binary variables. *__For this reason, a more general approach is to adopt Firth regression__*,36 which is a penalisation method that reduces small sample bias for non-linear models such as logistic regression, and resolves problems related to separation. Alternatively, researchers may revert to a one-stage IPD meta-analysis approach (Chapter 6),14,34 and placing random effects on parameters (rather than stratifying parameters by trial) so that estimation of trial-specific terms are avoided."
2. Time-to-event outcomes (page 102): "are few events in some trials adaptions of Firth’s correction are important to reduce small sample bias in the estimated treatment effect.45"
3. Alternative A: *__Add 0.5 correction__* to crosstab, calculate ORs and then inverse variance pooling in second stage
4. Alternative B: 2x2 directly into Mantel-Haenszel across several trials (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5297998/)? "The meta-analysis models described in Sections 5.3.1 and 5.3.2 are known as inverse variance meta-analysis methods. They combine trial estimates of treatment effect (i.e. θi), with weights accounting for the inverse of their estimated variances. "Both the common-effect and random-effects models of (5.10) and (5.14) assume that the treatment effect estimates in each trial are normally distributed and that their variances are know. Though these assumptions are appropriate when trials are reasonably large (in terms of number of participants and, if applicable, the number of events), they are more tenuous when trials are small or outcome events are rare;6,32,33 indeed, trial estimates of treatment effects and their variances may even be biased in such situations. To address this, other two-stage approaches have been proposed that use a different weighting scheme, such as the Mantel-Haenszel and Peto methods.99,100 For time-to-event outcomes, an extension to the Peto method is to calculate log hazard ratio estimates and variances based on the log-rank statistics in each trial, and then apply model (5.11). Simulation results suggest that, compared to the inverse variance method, the Peto method works well when treatment effects are small, event risks are <1%, and when treatment and control group sizes within trials are balanced (i.e. similar numbers allocated to each).6,32 A key advantage is that it does not require continuity corrections in trials with a zero event in either treatment or control groups." (p. 113)
5. Alternative C: *__However, this issue can also be addressed by applying a one-stage IPD meta-analysis model__* (Chapter 6), which is our preference as *__it can be more easily extended to more complex models, such as including prognostic factors and treatment-covariate interactions__*" (p. 113)

* BariSolidact: mort_28: 36 deaths (15 vs 21). 289 total. 12%
* ACTT2: mort_28: 61 deaths (24 vs 37). 1033 total. 6%
* Ghazaeian: mort_28: 7 deaths (3 vs 4). 97 total. 7% (but ae_28: only 1 AE grade 3,4)
* Tofacov: mort_28: 1 death. 116 total. 0.8%
* Covinib: mort_28: 2 deaths (0 vs 2). 110 total. 1.8%


## Missing data
1. For covariates of adjustment, see notes under first subtitle. For missing outcome data: "Some trials may have missing outcome values for some participants, with little or no missing data in covariates included in the analysis. Then, if missing outcomes are considered ‘missing at random’ (that is, that the probability of being missing depends only on the observed data for included covariates such as treatment and prognostic factors), Sullivan et al. recommend generally using complete-case analysis for a single outcome or a likelihood-based approach for multiple outcomes (e.g. linear mixed model for multiple continuous outcomes).78 *__They note that for randomised trials aiming to estimate a treatment effect, “multiple imputation can be inferior to complete-case analysis and likelihood-based approaches, adding in unnecessary simulation error” and that complete-case analysis “is optimal when missing data are restricted to a univariate outcome and variables associated with missingness are included as covariates in the analysis model__*”.78 This agrees with Groenwold et al., who state that for randomised trials “complete-case analysis with covariate adjustment and multiple imputation yield similar estimates in the event of missing outcome data, as long as the same predictors of missingness are included. Hence, complete case analysis with covariate adjustment can and should be used as the analysis of choice more often”.79 The missing at random assumption is more plausible when prognostic factors are included as adjustment covariates in the analysis model (or the imputation model80), which gives further weight to our recommendation to include a pre-defined set of prognostic factors (Section 5.2.4)." (p. 105)
2. "Where multiple imputation is used, it is important to impute separately for each randomised group as this offers greater robustness.78"  (p. 105)

a) BariSolidact:
* vacc: 5 missing -> MICE for subgroup analysis?
* mort_28: 12 missing
b) ACTT2: 
* sympdur & comorbities -> MICE for subgroup analysis?
* mort_28 (& mort_60): 47 missing
* new_mv_28 & new_mvd_28: 26 missing
c) Covinib: 3-5 missings in mort_28/mort_60/new_mv_28/new_mvd_28
d) Ghazaeian: No missing (besides 2 in CRP -> MICE for subgroup analysis?)
e) Tofacov: No missing (besides 1 in CRP -> MICE for subgroup analysis?)

* *__Decision 01.11.23__*: Do not use Complete Case, to keep ITT. Alternative imputation strategy (based on ACTT2 clinicalstatus day 15):
* Participant was randomized but had no clinical score data available for any timepoint (pre- or post-randomization): worse outcome but not death: 5 = ECMO/MV
* Participant was discharged from the hospital not due to death or transfer to hospice/another hospital and was not readmitted again: 1 = out of hospital
* Participant was discharged from the hospital due to transfer to hospice: 6 = death
* Participant was discharged from the hospital due to transfer to another hospital: last observed value carried forward
* Participant was withdrawn from the study while hospitalized (not due to death): last observed value carried forward

*__Chapter18__*


# TWO-STAGE APPROACH
"As the chosen regression model is estimated in each trial separately, a separate estimate of each parameter (i.e. αi , θi , β1i , β2i , ... is obtained for each trial. This process is also known as *__stratifying__* the estimation by trial, and implies that no information is shared across trials" (p. 93)

## Second stage
1. "Usually *__the assumption of a common treatment effect will be inappropriate__*, as the true effect of a treatment is likely to vary across trials. This is known as between-trial heterogeneity in treatment effect, and it occurs when the distribution of any treatment effect modifiers (i.e. methodological, clinical or participant-level characteristics that influence the magnitude of a treatment’s effect) varies across trials included in the IPD meta-analysis. Examples of potential effect modifiers include follow-up length, the dose of the treatment, the type of intervention in the control group (e.g. usual care), trial quality (risk of bias), and participant-level covariates that interact with treatment response. To allow for between-trial heterogeneity in treatment effect, the θi can be made random,89,90 such that *__the true treatment effects are allowed to be different but assumed to be drawn from a particular distribution, such as a normal distribution__*."
2. "Model (5.14) is often loosely termed a random-effects meta-analysis; however, it is more explicit to refer to it as a *__random treatment effects meta-analysis__* (indeed, in subsequent chapters we introduce IPD meta-analysis models that place random effects on multiple parameters, not just the treatment effect)." (p. 108/109)
3. "In this situation, the random weights (equation (5.17)) for each trial will be more similar to each other than the common weights (equation (5.13)), such that larger and smaller trials will be more equally weighted when assuming random rather than common treatment effects. Some readers may view this as controversial, but it is a consequence of allowing for the heterogeneity in treatment effects, and estimating the average of a distribution of true treatment effects, rather than a single common treatment effect. A more equal weighting is of most concern when smaller trials are at a higher risk of bias, as then the distribution of true treatment effects is potentially distorted by the smaller trials. *__Sensitivity analyses excluding trials at high risk of bias are important in this situation (Chapter 9)__*." (p. 109)
4. "*__I2 describes the percentage of variability in treatment effect estimates that is due to between-trial heterogeneity rather than chance.__* The value of I2 should not be used to decide between a common-effect or random-effects meta-analysis. Another common mistake is to interpret I2 as a measure of the (absolute) amount of heterogeneity (i.e. to consider I2 as an estimate of τ2). This is dangerous, as I2 depends on the size of the within-trial variances; for example, if all trials are small and thus s2i values are large, I2 can be small (i.e. close to 0%) even when the magnitude of τ2 is large and important.97 Rather, I2 should be viewed as a measure of the impact of heterogeneity (τ2) on the summary treatment effect estimate, with the impact small if I2 is close to 0% and large if I2 is close to 100%. The heterogeneity of treatment effects can also be quantified by using a 95% prediction interval for the treatment effect in a new trial" (p. 112)
5. "Both the common-effect and random-effects models of (5.10) and (5.14) assume that the treatment effect estimates in each trial are normally distributed and that their variances are know. Though these assumptions are appropriate when trials are reasonably large (in terms of number of participants and, if applicable, the number of events), they are more tenuous when trials are small or outcome events are rare;6,32,33 indeed, trial estimates of treatment effects and their variances may even be biased in such situations. To address this, other two-stage approaches have been proposed that use a different weighting scheme, such as the Mantel-Haenszel and Peto methods.99,100 For time-to-event outcomes, an extension to the Peto method is to calculate log hazard ratio estimates and variances based on the log-rank statistics in each trial, and then apply model (5.11). Simulation results suggest that, compared to the inverse variance method, the Peto method works well when treatment effects are small, event risks are <1%, and when treatment and control group sizes within trials are balanced (i.e. similar numbers allocated to each).6,32 A key advantage is that it does not require continuity corrections in trials with a zero event in either treatment or control groups. *__However, this issue can also be addressed by applying a one-stage IPD meta-analysis model__* (Chapter 6), which is our preference as *__it can be more easily extended to more complex models, such as including prognostic factors and treatment-covariate interactions__*" (p. 113)
6. "Therefore, generally we *__recommend REML for fitting meta-analysis models assuming random treatment effects__*, and this is used when applying model (5.14) in Box 5.4 and Box 5.5. However, it is not perfect; as for other estimation methods, *__it has poor properties when trial sizes are small or the event of interest is rare. In situations where REML does not converge, the Paule Mandel__* approach is a viable alternative.95,109" (p. 113)
7. "For example, following estimation of either models (5.10) or (5.14), a standard (‘Wald-based’) confidence interval for the summary treatment effect can be calculated. However, this approach does not account for the uncertainty in variance estimates, and so is likely to give confidence intervals that are too narrow. To address this, Hartung and Knapp111,112 (and also independently Sidik and Jonkman113) suggest using a modified confidence interval. When τ2 > 0, the HKSJ confidence interval will usually be wider than the standard confidence interval because it is based on the t-distribution, which has larger critical values (tS − 1,1 − α2 ) than the standard normal distribution. *__In summary, we generally recommend taking the HKSJ approach for deriving confidence intervals for the summary treatment effect following estimation of the random-effects meta-analysis model__* (5.14); however, if the standard method for deriving confidence intervals gives a wider interval than the HKSJ approach, then the standard confidence interval should (also) be presented.117" (p. 115)

## Prediction interval
1. "Predictive distributions are potentially the most relevant and complete statistical inferences to be drawn from random-effects meta-analyses.90" (p. 119)
2. Section 5.3.10

## Meta-regressions
1. page 120
* By risk of bias
* By different JAK inhibitors

## Combining IPD Trials with Partially Reconstructed IPD from Non-IPD Trials
1. "For binary outcome data, IPD can be partly reconstructed from the aggregated information in published two-by-two tables.8 For example, if the number of participants who were dead and alive for each of the treatment and control groups is known, IPD can be re-created in a binary data format, where control/treatment group and alive/dead are represented by a series of zeros and ones. This is illustrated in Box 6.5." (p. 160)
2. Add CTI biopharma trial and Murugesan (?) for primary endpoint - and what about subgroup analyses?

3. Also, see p.127


# ONE-STAGE APPROACH
"__A potential concern, however, is that the second stage [of the two-stage approach] assumes treatment effect estimates in each trial are normally distributed and that their variances are known; this may be problematic when most trials in the meta-analysis are small (in terms of number of participants and/or events), and motivates rather using the one-stage approach described in the next chapter.__"

## Setting the right parameters/assumptions and general comments
1. "One-stage IPD meta-analysis models usually include multiple parameters and these are estimated simultaneously. *__For each parameter (such as the intercept, treatment effect, residual variances) the analyst must specify whether they are common (the same in each trial), stratified (different in each trial) or random__* (different in each trial and assumed drawn from a particular distribution)." (p.127)
2. "A *__stratified trial intercept__* is generally preferred, unless there are computational concerns. The use of random trial intercepts allows information about baseline risk to be shared across trials, which may compromise randomisation within each trial." (p.127)
3. "For binary outcomes, unless most included trials have sparse numbers of events, REML estimation of a pseudo-likelihood is recommended." (p.127)
4. "The one-stage modelling framework can be extended to accommodate non-proportional hazards, trials with different designs and inclusion of aggregate data from non-IPD trials." (p.127)
5. "Researchers must pre-specify and report their one-stage model specification and assumptions" (p.127)
6. "A one-stage IPD meta-analysis utilises a more exact statistical likelihood than a two-stage meta-analysis approach, which is advantageous when included trials have few participants or outcome events." (p.127)
7. "Compared to a two-stage approach to IPD meta-analysis (Chapter 5), *__a major advantage of one-stage models for binary (and multinomial, ordinal or count) outcomes is the ability to handle trials that contain a group with no participants who have the outcome event (or conversely no participants without the outcome event).__*14,147,157,166 This is due to modelling the binomial likelihood directly, and avoids the need for continuity corrections, unlike the two-stage approach. Thus, one-stage models are especially important when trials contain small numbers of participants or events. Including trials with double zeros (i.e. both groups have no participants with the outcome event, or conversely all participants have the outcome event) is not recommended, as they provide no information about the treatment effect unless additional assumptions are made. Where data are sparse, one-stage models for binary outcomes are prone to potential bias in summary odds ratios,98 although any bias should be less than occurs for the two-stage approach, where data are even more sparse due to deriving trial-specific estimates separately in the first stage." (p.127)
8. "The meta-analysis literature traditionally uses the words common and fixed interchangeably; in particular, the phrase ‘fixed-effect meta-analysis’ is usually short-hand for a meta- analysis that assumes the treatment effect is common to all trials. This is unhelpful in the context of a one-stage IPD meta-analysis for various reasons. Firstly, there are multiple parameters within a one-stage model, and so loosely stating that a ‘fixed-effect IPD meta-analysis was used’ does not reveal which parameter (or parameters) the word ‘fixed’ actually refers to. Secondly, the word ‘fixed’ is ambiguous; it could refer to either a common or stratified parameter, even though they imply different model specifications and assumptions. *__Therefore, we recommend that the word ‘fixed’ be avoided in one-stage IPD models__*, and encourage researchers to use common or stratified instead. As the one-stage model produces multiple parameter estimates, is also helpful to replace vague wording such as ‘common-effect meta-analysis’ or ‘random-effects meta-analysis’ *__with more explicit wording about which parameters in the model are being assumed common or random (or stratified)__*. This is especially important when the one-stage model equation is not actually provided." (p. 138)
9. "*__Assuming a parameter is stratified requires a separate value of the parameter to be estimated for each trial_*; it allows the *__true value of each parameter to be trial-specific__*, without making any assumption about the distribution of the parameter values across trials. For example, allowing for a stratified intercept when there are 10 trials is equivalent to specifying 10 intercepts, one for each trial. This may be acceptable for so-called nuisance parameters (i.e. those parameters not of direct interest, such as the trial-specific intercepts, prognostic factor effects, residual variances, etc). However, stratification is unhelpful for those parameters requiring summary inferences, such as the treatment effect, and rather these must be assumed common or random. Homogeneity of treatment effect is a strong assumption, and often will be inappropriate due to unexplained between-trial heterogeneity (Section 5.3.2). To address this, the treatment effect parameter can be made random, such that the true treatment effect in each trial is assumed drawn from a particular distribution, typically a normal distribution." (p. 138)
10. "*__Importantly, even when allowing the treatment effects to be random, the nuisance parameters within the GLMM (i.e. those parameters other than the treatment effect) are still stratified by trial__*. This is needed to account for clustering of participants within trials, and to allow for potential between-trial heterogeneity in baseline risk and prognostic effects. An alternative option is to assume nuisance parameters are random. Section 6.2.4.2 discusses the choice between random and stratified parameters in more detail. *__Many researchers assume nuisance parameters are common (often because this is the default in software packages), but this is not recommended as it may lead to inappropriate conclusions.__*" (p. 138)
11. "The *__advantage of the stratified intercept approach is that it makes no assumptions about the distribution of intercepts across trials__* - *__and mirrors exactly the two-stage approach__*. The advantage of the random intercepts approach is that it requires fewer parameters to be estimated and so may reduce model convergence issues. But usually they give very similar results." (p. 141 & 143)
12. "Therefore, when fitting a one-stage model with random intercepts and random treatment effects, Turner et al. suggest the correlation should be accounted for and a 1/0 treatment variable coding used.157 If the correlation is not estimable, then assuming it is zero and using a +0.5/–0.5 treatment variable coding is sensible." (p. 144)
13. "Our *__default recommendation is to use stratified prognostic effects (i.e. estimate a separate effect of each included prognostic factor for each trial), with trial-specific centering of each prognostic factor to improve ML estimation__* (for the reasons explained in Section 6.2.8.3). However, if outcome data or prognostic factor categories are sparse, the stratification approach may lead to estimation difficulties, and then allowing prognostic factor effects to be random is a sensible alternative." (p. 145)
14."Unfortunately, there is no natural extension from ML to REML estimation for the exact likelihood defined by a GLMM of a binary, ordinal or count outcome, as the model residuals cannot be estimated separately from the main parameters. Thus ML estimation is generally the default estimation choice for GLMMs of non-continuous outcomes, for which downward bias in between-trial variance estimates and low coverage of confidence intervals is a strong concern, especially with a small number of trials in the IPD meta-analysis. To address this issue, Wolfinger and O’Connell suggest using a pseudo-likelihood approximation of the exact likelihood,199 where the outcome response variable is transformed to an approximately linear scale. This allows REML to be used for GLMMs of non-continuous outcomes, but at the expense of an approximate likelihood. This may be an acceptable trade-off in some situations, to improve between-trial variance estimates and confidence interval coverage. For example, when there are, say, 15 or fewer trials in the IPD meta-analysis, and most have reasonable numbers of participants and events, REML estimation of the pseudo-likelihood may be a good approximation and perform much better than ML estimation of the exact likelihood.200 REML also allows the Kenward-Roger or Satterthwaite corrections to the confidence interval. *__However, this REML approach may not be appropriate when data are sparse (i.e. most trials are small and have few or even zero events)__*, as other work indicates the pseudo-likelihood is not accurate in sparse data situations.153 Problems with REML estimation of the pseudo-likelihood are revealed when parameter estimates are unstable. Instability is evident when first-order and second-order linearisation of the likelihood lead to very different parameter estimates, or when different parameterisations that should not affect REML (such as centering of covariates) change parameter estimates importantly. *__In such situations, ML estimation of the exact likelihood is preferred.__* " (p. 148)
15. "*__Trial-specific Centering of Variables to Improve ML Estimation of One-stage__*: Models with a Stratified Intercept. As previously discussed (Section 6.2.4.1), Jackson et al. and Riley et al. show that for one-stage models with a stratified intercept, *__ML estimation is improved when using trial-specific centering of treatment and other included variables.__*181,185 *__Centering disentangles (i.e. makes uncorrelated) the estimation of main parameters of interest from other nuisance parameters, which leads to less downward bias in estimates of variance parameters (Figure 6.2) and thus improves coverage of 95% confidence intervals.__*" (p. 147)


## The main recommendations for one-stage IPD meta-analysis models using GLMMs summarized (Box 6.4)
1. *__Use a random treatment effect.__*
Justification: Typically the included trials are conducted in different settings, populations and time periods. Therefore, some heterogeneity of treatment effect is expected. Heterogeneity might be reduced by inclusion of prognostic factors (Section 6.2.6) or trial-level covariates (6.2.7), but usually unexplained heterogeneity remains and so should be acknowledged.
2. *__Stratify by trial the intercept and parameters for other non-treatment variables (such as prognostic factors and residual variances)__*. If convergence issues arise, then consider making the intercept (and other non-treatment variables) random.
Justification: Although a random intercept will usually give similar results to a stratified inter- cept, in some situations it may compromise randomisation (as it allows baseline risk informa- tion to be shared across trials). If a stratified intercept model fails to converge (e.g. with rare events or many parameters), assuming random intercepts is a sensible compromise, in which case accounting for the correlation between the random effects on intercept and treatment effect may be important. Another option is to entirely condition out the trial intercepts (Section 6.2.4.2).
3. *__Use trial-specific centering of the treatment variable (and any other included variables, such as prognostic factors) when using ML estimation of a one-stage model with a stratified intercept.__* Justification: Simulation studies and mathematical reasoning show that this improves ML estimation of between-trial variances and the coverage of confidence intervals for the summary treatment effect (Section 6.2.8.3).
4. For frequentist estimation of one-stage models for binary, ordinal or count outcomes, use REML estimation of the pseudo-likelihood approach unless most trials in the meta-analysis are small (in terms of participants or outcome events), which then warrants ML estimation of the exact likelihood.
Justification: Although estimation of the exact likelihood is preferred, ML estimation is known to produce downwardly biased estimates of between-trial variances. Therefore, unless most included trials are small, REML estimation of an approximate pseudo-likelihood specification may improve estimation of between-trial variances and coverage of confidence intervals (Section 6.2.8.4). When either REML or ML estimation is used, coverage is improved using confidence intervals based on the t-distribution (Section 6.2.8.5). A Bayesian approach is an appealing alternative.

Also, check out: Adapted from Simmonds MC, Higgins JP. A general framework for the use of logistic regression models in meta-analysis. Stat Methods Med Res 2016;25(6):2858–77.

And, for time to event outcomes: https://eprints.keele.ac.uk/id/eprint/7367/1/Manuscript%20-%20Individual%20participant%20data%20meta-analysis%20of%20intervention%20studies%20with%20time-to-event%20outcomes%20A%20review%20of%20the%20methodology%20and%20an%20applied%20example.pdf 



```{r}

```
